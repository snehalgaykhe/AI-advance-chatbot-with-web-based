{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba03bcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask-cors\n",
      "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting flask>=0.9 (from flask-cors)\n",
      "  Downloading flask-3.1.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting Werkzeug>=0.7 (from flask-cors)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting blinker>=1.9.0 (from flask>=0.9->flask-cors)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting click>=8.1.3 (from flask>=0.9->flask-cors)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting itsdangerous>=2.2.0 (from flask>=0.9->flask-cors)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting jinja2>=3.1.2 (from flask>=0.9->flask-cors)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting markupsafe>=2.1.1 (from flask>=0.9->flask-cors)\n",
      "  Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\snehal\\appdata\\roaming\\python\\python313\\site-packages (from click>=8.1.3->flask>=0.9->flask-cors) (0.4.6)\n",
      "Downloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
      "Downloading flask-3.1.2-py3-none-any.whl (103 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: markupsafe, itsdangerous, click, blinker, Werkzeug, jinja2, flask, flask-cors\n",
      "\n",
      "   ----- ---------------------------------- 1/8 [itsdangerous]\n",
      "   ---------- ----------------------------- 2/8 [click]\n",
      "   ---------- ----------------------------- 2/8 [click]\n",
      "   ---------- ----------------------------- 2/8 [click]\n",
      "   --------------- ------------------------ 3/8 [blinker]\n",
      "   -------------------- ------------------- 4/8 [Werkzeug]\n",
      "   -------------------- ------------------- 4/8 [Werkzeug]\n",
      "   -------------------- ------------------- 4/8 [Werkzeug]\n",
      "   -------------------- ------------------- 4/8 [Werkzeug]\n",
      "   -------------------- ------------------- 4/8 [Werkzeug]\n",
      "   -------------------- ------------------- 4/8 [Werkzeug]\n",
      "   -------------------- ------------------- 4/8 [Werkzeug]\n",
      "   -------------------- ------------------- 4/8 [Werkzeug]\n",
      "   ------------------------- -------------- 5/8 [jinja2]\n",
      "   ------------------------- -------------- 5/8 [jinja2]\n",
      "   ------------------------- -------------- 5/8 [jinja2]\n",
      "   ------------------------- -------------- 5/8 [jinja2]\n",
      "   ------------------------- -------------- 5/8 [jinja2]\n",
      "   ------------------------------ --------- 6/8 [flask]\n",
      "   ------------------------------ --------- 6/8 [flask]\n",
      "   ------------------------------ --------- 6/8 [flask]\n",
      "   ------------------------------ --------- 6/8 [flask]\n",
      "   ------------------------------ --------- 6/8 [flask]\n",
      "   ----------------------------------- ---- 7/8 [flask-cors]\n",
      "   ---------------------------------------- 8/8 [flask-cors]\n",
      "\n",
      "Successfully installed Werkzeug-3.1.3 blinker-1.9.0 click-8.2.1 flask-3.1.2 flask-cors-6.0.1 itsdangerous-2.2.0 jinja2-3.1.6 markupsafe-3.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask-cors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b0c4bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.102.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\snehal\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\snehal\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\snehal\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.2-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\snehal\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.102.0-py3-none-any.whl (812 kB)\n",
      "   ---------------------------------------- 0.0/812.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/812.0 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 524.3/812.0 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 812.0/812.0 kB 1.9 MB/s  0:00:00\n",
      "Downloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.10.0-cp313-cp313-win_amd64.whl (205 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.3/2.0 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/2.0 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/2.0 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/2.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/2.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 1.1 MB/s  0:00:01\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, tqdm, sniffio, pydantic-core, jiter, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   --- ------------------------------------  1/13 [tqdm]\n",
      "   ------ ---------------------------------  2/13 [sniffio]\n",
      "   --------- ------------------------------  3/13 [pydantic-core]\n",
      "   --------------- ------------------------  5/13 [h11]\n",
      "   --------------- ------------------------  5/13 [h11]\n",
      "   ------------------ ---------------------  6/13 [distro]\n",
      "   ------------------ ---------------------  6/13 [distro]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   ------------------------ ---------------  8/13 [pydantic]\n",
      "   --------------------------- ------------  9/13 [httpcore]\n",
      "   --------------------------- ------------  9/13 [httpcore]\n",
      "   --------------------------- ------------  9/13 [httpcore]\n",
      "   --------------------------- ------------  9/13 [httpcore]\n",
      "   --------------------------- ------------  9/13 [httpcore]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   ------------------------------ --------- 10/13 [anyio]\n",
      "   --------------------------------- ------ 11/13 [httpx]\n",
      "   --------------------------------- ------ 11/13 [httpx]\n",
      "   --------------------------------- ------ 11/13 [httpx]\n",
      "   --------------------------------- ------ 11/13 [httpx]\n",
      "   --------------------------------- ------ 11/13 [httpx]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ------------------------------------ --- 12/13 [openai]\n",
      "   ---------------------------------------- 13/13 [openai]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.10.0 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.10.0 openai-1.102.0 pydantic-2.11.7 pydantic-core-2.33.2 sniffio-1.3.1 tqdm-4.67.1 typing-inspection-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d97669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 12:37:18,283 - __main__ - INFO - OpenAI client initialized successfully\n",
      "2025-08-28 12:37:18,294 - __main__ - INFO - ==================================================\n",
      "2025-08-28 12:37:18,295 - __main__ - INFO - Starting Advanced AI Chatbot Server\n",
      "2025-08-28 12:37:18,296 - __main__ - INFO - ==================================================\n",
      "2025-08-28 12:37:18,297 - __main__ - INFO - Model: microsoft/mai-ds-r1:free\n",
      "2025-08-28 12:37:18,298 - __main__ - INFO - Base URL: https://openrouter.ai/api/v1\n",
      "2025-08-28 12:37:18,299 - __main__ - INFO - API Key configured: True\n",
      "2025-08-28 12:37:18,300 - __main__ - INFO - Client initialized: True\n",
      "2025-08-28 12:37:18,301 - __main__ - INFO - Starting Flask server on http://0.0.0.0:5000\n",
      "2025-08-28 12:37:18,301 - __main__ - INFO - Visit http://localhost:5000 to test the chatbot\n",
      "2025-08-28 12:37:18,302 - __main__ - INFO - API endpoints available at /api/*\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 12:37:18,313 - werkzeug - INFO - \u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.50:5000\n",
      "2025-08-28 12:37:18,315 - werkzeug - INFO - \u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "2025-08-28 12:37:37,012 - werkzeug - INFO - 127.0.0.1 - - [28/Aug/2025 12:37:37] \"GET / HTTP/1.1\" 200 -\n",
      "2025-08-28 12:37:37,338 - werkzeug - INFO - 127.0.0.1 - - [28/Aug/2025 12:37:37] \"GET /api/health HTTP/1.1\" 200 -\n",
      "2025-08-28 12:37:57,819 - __main__ - INFO - Processing chat request - Session: session_..., Message: hiiiii...\n",
      "2025-08-28 12:37:57,824 - __main__ - INFO - Generating response for session: session_...\n",
      "2025-08-28 12:38:03,511 - httpx - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 12:38:05,591 - __main__ - INFO - Response generated successfully for session: session_...\n",
      "2025-08-28 12:38:05,592 - __main__ - INFO - Chat request completed successfully for session: session_...\n",
      "2025-08-28 12:38:05,594 - werkzeug - INFO - 127.0.0.1 - - [28/Aug/2025 12:38:05] \"POST /api/chat HTTP/1.1\" 200 -\n",
      "2025-08-28 12:38:42,186 - __main__ - INFO - Processing chat request - Session: session_..., Message: Tell me about the difference between Data Science ...\n",
      "2025-08-28 12:38:42,190 - __main__ - INFO - Generating response for session: session_...\n",
      "2025-08-28 12:38:44,109 - httpx - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 12:38:54,585 - __main__ - INFO - Response generated successfully for session: session_...\n",
      "2025-08-28 12:38:54,586 - __main__ - INFO - Chat request completed successfully for session: session_...\n",
      "2025-08-28 12:38:54,587 - werkzeug - INFO - 127.0.0.1 - - [28/Aug/2025 12:38:54] \"POST /api/chat HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template_string\n",
    "from flask_cors import CORS\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "from werkzeug.exceptions import BadRequest\n",
    "import re\n",
    "import uuid\n",
    "import sys\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app, resources={r\"/api/*\": {\"origins\": \"*\"}})\n",
    "\n",
    "# Configuration\n",
    "class Config:\n",
    "    OPENAI_API_KEY = \"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\"\n",
    "    OPENAI_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
    "    MODEL_NAME = \"microsoft/mai-ds-r1:free\"\n",
    "    MAX_TOKENS = 1000\n",
    "    TEMPERATURE = 0.7\n",
    "    SITE_URL = \"http://localhost:5000\"\n",
    "    SITE_NAME = \"Advanced AI Chatbot\"\n",
    "\n",
    "# Global client variable\n",
    "client = None\n",
    "\n",
    "def initialize_openai_client():\n",
    "    \"\"\"Initialize OpenAI client with proper error handling\"\"\"\n",
    "    global client\n",
    "    try:\n",
    "        client = OpenAI(\n",
    "            base_url=Config.OPENAI_BASE_URL,\n",
    "            api_key=Config.OPENAI_API_KEY,\n",
    "            timeout=30.0  # Add timeout\n",
    "        )\n",
    "        logger.info(\"OpenAI client initialized successfully\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize OpenAI client: {str(e)}\")\n",
    "        client = None\n",
    "        return False\n",
    "\n",
    "# Initialize client on startup\n",
    "client_initialized = initialize_openai_client()\n",
    "\n",
    "# In-memory conversation storage\n",
    "conversations = {}\n",
    "\n",
    "class ChatbotService:\n",
    "    @staticmethod\n",
    "    def get_system_prompt():\n",
    "        return \"\"\"You are an advanced AI assistant chatbot. You are helpful, knowledgeable, and friendly.\n",
    "        Provide clear, concise, and accurate responses. If you're unsure about something, acknowledge it.\n",
    "        Always maintain a professional yet approachable tone.\"\"\"\n",
    "   \n",
    "    @staticmethod\n",
    "    def sanitize_input(text):\n",
    "        \"\"\"Basic input sanitization\"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return \"\"\n",
    "        # Remove excessive whitespace and limit length\n",
    "        text = re.sub(r'\\s+', ' ', text.strip())\n",
    "        return text[:2000]\n",
    "   \n",
    "    @staticmethod\n",
    "    def get_conversation(session_id):\n",
    "        \"\"\"Retrieve conversation history\"\"\"\n",
    "        if session_id not in conversations:\n",
    "            conversations[session_id] = {\n",
    "                \"messages\": [{\"role\": \"system\", \"content\": ChatbotService.get_system_prompt()}],\n",
    "                \"created_at\": datetime.now().isoformat(),\n",
    "                \"last_activity\": datetime.now().isoformat()\n",
    "            }\n",
    "        return conversations[session_id]\n",
    "   \n",
    "    @staticmethod\n",
    "    def add_message(session_id, role, content):\n",
    "        \"\"\"Add message to conversation\"\"\"\n",
    "        conv = ChatbotService.get_conversation(session_id)\n",
    "        conv[\"messages\"].append({\"role\": role, \"content\": content})\n",
    "        conv[\"last_activity\"] = datetime.now().isoformat()\n",
    "       \n",
    "        # Keep only last 20 messages (excluding system message)\n",
    "        if len(conv[\"messages\"]) > 21:\n",
    "            conv[\"messages\"] = [conv[\"messages\"][0]] + conv[\"messages\"][-20:]\n",
    "   \n",
    "    @staticmethod\n",
    "    def generate_response(session_id, user_message):\n",
    "        \"\"\"Generate AI response\"\"\"\n",
    "        try:\n",
    "            # Check if client is initialized\n",
    "            if client is None:\n",
    "                logger.error(\"OpenAI client is not initialized\")\n",
    "                return {\"error\": \"AI service is not available. Please check configuration.\"}\n",
    "           \n",
    "            # Sanitize input\n",
    "            user_message = ChatbotService.sanitize_input(user_message)\n",
    "            if not user_message:\n",
    "                return {\"error\": \"Invalid or empty message\"}\n",
    "           \n",
    "            # Add user message to conversation\n",
    "            ChatbotService.add_message(session_id, \"user\", user_message)\n",
    "            conv = ChatbotService.get_conversation(session_id)\n",
    "           \n",
    "            logger.info(f\"Generating response for session: {session_id[:8]}...\")\n",
    "           \n",
    "            # Make API call\n",
    "            try:\n",
    "                response = client.chat.completions.create(\n",
    "                    extra_headers={\n",
    "                        \"HTTP-Referer\": Config.SITE_URL,\n",
    "                        \"X-Title\": Config.SITE_NAME,\n",
    "                    },\n",
    "                    model=Config.MODEL_NAME,\n",
    "                    messages=conv[\"messages\"],\n",
    "                    max_tokens=Config.MAX_TOKENS,\n",
    "                    temperature=Config.TEMPERATURE,\n",
    "                )\n",
    "               \n",
    "                # Validate response\n",
    "                if not response or not response.choices or len(response.choices) == 0:\n",
    "                    logger.error(\"No response choices returned from API\")\n",
    "                    return {\"error\": \"No response generated from AI model\"}\n",
    "               \n",
    "                ai_response = response.choices[0].message.content\n",
    "               \n",
    "                if not ai_response:\n",
    "                    logger.error(\"Empty response content from API\")\n",
    "                    return {\"error\": \"Empty response from AI model\"}\n",
    "               \n",
    "            except Exception as api_error:\n",
    "                logger.error(f\"OpenAI API error: {str(api_error)}\")\n",
    "                return {\"error\": f\"AI service temporarily unavailable: {type(api_error).__name__}\"}\n",
    "           \n",
    "            # Add AI response to conversation\n",
    "            ChatbotService.add_message(session_id, \"assistant\", ai_response)\n",
    "           \n",
    "            logger.info(f\"Response generated successfully for session: {session_id[:8]}...\")\n",
    "           \n",
    "            return {\n",
    "                \"response\": ai_response,\n",
    "                \"session_id\": session_id,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"model\": Config.MODEL_NAME,\n",
    "                \"status\": \"success\"\n",
    "            }\n",
    "           \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error in generate_response: {str(e)}\")\n",
    "            return {\n",
    "                \"error\": f\"Service error: {type(e).__name__}\",\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "\n",
    "# Enhanced HTML template\n",
    "HTML_TEMPLATE = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <title>AI Chatbot - Test Interface</title>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
    "    <style>\n",
    "        * { box-sizing: border-box; }\n",
    "        body {\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "            margin: 0; padding: 20px;\n",
    "            background-color: #f5f5f5;\n",
    "        }\n",
    "        .chat-container {\n",
    "            max-width: 800px;\n",
    "            margin: 0 auto;\n",
    "            background: white;\n",
    "            border-radius: 10px;\n",
    "            box-shadow: 0 2px 10px rgba(0,0,0,0.1);\n",
    "            overflow: hidden;\n",
    "        }\n",
    "        .header {\n",
    "            background: #2196F3;\n",
    "            color: white;\n",
    "            padding: 20px;\n",
    "            text-align: center;\n",
    "        }\n",
    "        .header h1 { margin: 0; }\n",
    "        .status {\n",
    "            padding: 10px 20px;\n",
    "            background: #e8f5e8;\n",
    "            border-left: 4px solid #4caf50;\n",
    "            margin: 0;\n",
    "        }\n",
    "        .status.error {\n",
    "            background: #ffeaea;\n",
    "            border-left-color: #f44336;\n",
    "            color: #d32f2f;\n",
    "        }\n",
    "        #messages {\n",
    "            height: 400px;\n",
    "            overflow-y: auto;\n",
    "            padding: 20px;\n",
    "            background: #fafafa;\n",
    "        }\n",
    "        .message {\n",
    "            margin: 15px 0;\n",
    "            padding: 12px 16px;\n",
    "            border-radius: 18px;\n",
    "            max-width: 80%;\n",
    "            word-wrap: break-word;\n",
    "        }\n",
    "        .user {\n",
    "            background: #2196F3;\n",
    "            color: white;\n",
    "            margin-left: auto;\n",
    "            text-align: right;\n",
    "        }\n",
    "        .assistant {\n",
    "            background: white;\n",
    "            border: 1px solid #e0e0e0;\n",
    "        }\n",
    "        .error {\n",
    "            background: #ffcdd2;\n",
    "            color: #c62828;\n",
    "            border: 1px solid #ef5350;\n",
    "        }\n",
    "        .input-area {\n",
    "            padding: 20px;\n",
    "            background: white;\n",
    "            border-top: 1px solid #e0e0e0;\n",
    "        }\n",
    "        .input-group {\n",
    "            display: flex;\n",
    "            gap: 10px;\n",
    "        }\n",
    "        input[type=\"text\"] {\n",
    "            flex: 1;\n",
    "            padding: 12px 16px;\n",
    "            border: 1px solid #ddd;\n",
    "            border-radius: 25px;\n",
    "            outline: none;\n",
    "            font-size: 14px;\n",
    "        }\n",
    "        input[type=\"text\"]:focus {\n",
    "            border-color: #2196F3;\n",
    "        }\n",
    "        button {\n",
    "            padding: 12px 20px;\n",
    "            border: none;\n",
    "            border-radius: 25px;\n",
    "            cursor: pointer;\n",
    "            font-weight: 500;\n",
    "            transition: all 0.2s;\n",
    "        }\n",
    "        .send-btn {\n",
    "            background: #2196F3;\n",
    "            color: white;\n",
    "        }\n",
    "        .send-btn:hover {\n",
    "            background: #1976D2;\n",
    "        }\n",
    "        .send-btn:disabled {\n",
    "            background: #ccc;\n",
    "            cursor: not-allowed;\n",
    "        }\n",
    "        .clear-btn {\n",
    "            background: #f44336;\n",
    "            color: white;\n",
    "        }\n",
    "        .clear-btn:hover {\n",
    "            background: #d32f2f;\n",
    "        }\n",
    "        .loading {\n",
    "            display: none;\n",
    "            color: #666;\n",
    "            font-style: italic;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"chat-container\">\n",
    "        <div class=\"header\">\n",
    "            <h1>ðŸ¤– AI Chatbot</h1>\n",
    "            <div>Test Interface</div>\n",
    "        </div>\n",
    "       \n",
    "        <div id=\"status\" class=\"status\">\n",
    "            System ready - Type a message to start chatting\n",
    "        </div>\n",
    "       \n",
    "        <div id=\"messages\"></div>\n",
    "       \n",
    "        <div class=\"input-area\">\n",
    "            <div class=\"input-group\">\n",
    "                <input\n",
    "                    type=\"text\"\n",
    "                    id=\"messageInput\"\n",
    "                    placeholder=\"Type your message here...\"\n",
    "                    onkeypress=\"if(event.key==='Enter' && !event.shiftKey) { event.preventDefault(); sendMessage(); }\"\n",
    "                    maxlength=\"2000\"\n",
    "                >\n",
    "                <button id=\"sendBtn\" class=\"send-btn\" onclick=\"sendMessage()\">Send</button>\n",
    "                <button class=\"clear-btn\" onclick=\"clearChat()\">Clear</button>\n",
    "            </div>\n",
    "            <div id=\"loading\" class=\"loading\">AI is thinking...</div>\n",
    "        </div>\n",
    "    </div>\n",
    "\n",
    "    <script>\n",
    "        const sessionId = 'session_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);\n",
    "        let isProcessing = false;\n",
    "       \n",
    "        function updateStatus(message, isError = false) {\n",
    "            const status = document.getElementById('status');\n",
    "            status.textContent = message;\n",
    "            status.className = isError ? 'status error' : 'status';\n",
    "        }\n",
    "       \n",
    "        function addMessage(role, content, isError = false) {\n",
    "            const messages = document.getElementById('messages');\n",
    "            const messageDiv = document.createElement('div');\n",
    "            messageDiv.className = 'message ' + (isError ? 'error' : role);\n",
    "            messageDiv.textContent = content;\n",
    "            messages.appendChild(messageDiv);\n",
    "            messages.scrollTop = messages.scrollHeight;\n",
    "        }\n",
    "       \n",
    "        function setLoading(loading) {\n",
    "            const sendBtn = document.getElementById('sendBtn');\n",
    "            const loadingDiv = document.getElementById('loading');\n",
    "            const input = document.getElementById('messageInput');\n",
    "           \n",
    "            isProcessing = loading;\n",
    "            sendBtn.disabled = loading;\n",
    "            loadingDiv.style.display = loading ? 'block' : 'none';\n",
    "           \n",
    "            if (loading) {\n",
    "                sendBtn.textContent = 'Wait...';\n",
    "                input.disabled = true;\n",
    "            } else {\n",
    "                sendBtn.textContent = 'Send';\n",
    "                input.disabled = false;\n",
    "                input.focus();\n",
    "            }\n",
    "        }\n",
    "       \n",
    "        async function sendMessage() {\n",
    "            const input = document.getElementById('messageInput');\n",
    "            const message = input.value.trim();\n",
    "           \n",
    "            if (!message || isProcessing) return;\n",
    "           \n",
    "            addMessage('user', message);\n",
    "            input.value = '';\n",
    "            setLoading(true);\n",
    "            updateStatus('Sending message...');\n",
    "           \n",
    "            try {\n",
    "                const response = await fetch('/api/chat', {\n",
    "                    method: 'POST',\n",
    "                    headers: {\n",
    "                        'Content-Type': 'application/json',\n",
    "                    },\n",
    "                    body: JSON.stringify({\n",
    "                        message: message,\n",
    "                        session_id: sessionId\n",
    "                    })\n",
    "                });\n",
    "               \n",
    "                const data = await response.json();\n",
    "               \n",
    "                if (!response.ok) {\n",
    "                    throw new Error(`Server error: ${response.status}`);\n",
    "                }\n",
    "               \n",
    "                if (data.error) {\n",
    "                    addMessage('assistant', 'Error: ' + data.error, true);\n",
    "                    updateStatus('Error occurred', true);\n",
    "                } else {\n",
    "                    addMessage('assistant', data.response);\n",
    "                    updateStatus('Message sent successfully');\n",
    "                }\n",
    "               \n",
    "            } catch (error) {\n",
    "                console.error('Request failed:', error);\n",
    "                addMessage('assistant', `Connection error: ${error.message}`, true);\n",
    "                updateStatus('Connection failed', true);\n",
    "            } finally {\n",
    "                setLoading(false);\n",
    "            }\n",
    "        }\n",
    "       \n",
    "        async function clearChat() {\n",
    "            if (!confirm('Are you sure you want to clear the chat?')) return;\n",
    "           \n",
    "            try {\n",
    "                await fetch(`/api/conversation/${sessionId}`, {\n",
    "                    method: 'DELETE'\n",
    "                });\n",
    "                document.getElementById('messages').innerHTML = '';\n",
    "                updateStatus('Chat cleared');\n",
    "            } catch (error) {\n",
    "                console.error('Error clearing chat:', error);\n",
    "                updateStatus('Failed to clear chat', true);\n",
    "            }\n",
    "        }\n",
    "       \n",
    "        // Initialize\n",
    "        document.getElementById('messageInput').focus();\n",
    "       \n",
    "        // Check API health on load\n",
    "        fetch('/api/health')\n",
    "            .then(r => r.json())\n",
    "            .then(data => {\n",
    "                updateStatus(`System ready - AI service: ${data.ai_service || 'unknown'}`);\n",
    "            })\n",
    "            .catch(() => {\n",
    "                updateStatus('Warning: Could not connect to API', true);\n",
    "            });\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Routes\n",
    "@app.route('/')\n",
    "def index():\n",
    "    \"\"\"Serve the main chat interface\"\"\"\n",
    "    return render_template_string(HTML_TEMPLATE)\n",
    "\n",
    "@app.route('/api/chat', methods=['POST'])\n",
    "def chat():\n",
    "    \"\"\"Main chat endpoint\"\"\"\n",
    "    try:\n",
    "        if not request.is_json:\n",
    "            logger.warning(\"Received non-JSON request\")\n",
    "            return jsonify({\"error\": \"Request must be JSON\"}), 400\n",
    "           \n",
    "        data = request.get_json()\n",
    "       \n",
    "        if not data:\n",
    "            logger.warning(\"Received empty request data\")\n",
    "            return jsonify({\"error\": \"No data provided\"}), 400\n",
    "           \n",
    "        if 'message' not in data:\n",
    "            logger.warning(\"Received request without message field\")\n",
    "            return jsonify({\"error\": \"Message field is required\"}), 400\n",
    "       \n",
    "        user_message = data.get('message', '').strip()\n",
    "        session_id = data.get('session_id', str(uuid.uuid4()))\n",
    "       \n",
    "        if not user_message:\n",
    "            return jsonify({\"error\": \"Message cannot be empty\"}), 400\n",
    "       \n",
    "        logger.info(f\"Processing chat request - Session: {session_id[:8]}..., Message: {user_message[:50]}...\")\n",
    "       \n",
    "        # Generate response\n",
    "        result = ChatbotService.generate_response(session_id, user_message)\n",
    "       \n",
    "        if 'error' in result:\n",
    "            logger.error(f\"Response generation failed: {result['error']}\")\n",
    "            return jsonify(result), 500\n",
    "       \n",
    "        logger.info(f\"Chat request completed successfully for session: {session_id[:8]}...\")\n",
    "        return jsonify(result)\n",
    "       \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error in chat endpoint: {str(e)}\", exc_info=True)\n",
    "        return jsonify({\n",
    "            \"error\": f\"Internal server error: {type(e).__name__}\",\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }), 500\n",
    "\n",
    "@app.route('/api/conversation/<session_id>', methods=['GET'])\n",
    "def get_conversation_history(session_id):\n",
    "    \"\"\"Get conversation history\"\"\"\n",
    "    try:\n",
    "        conv = ChatbotService.get_conversation(session_id)\n",
    "        messages = [msg for msg in conv[\"messages\"] if msg[\"role\"] != \"system\"]\n",
    "        return jsonify({\n",
    "            \"messages\": messages,\n",
    "            \"session_id\": session_id,\n",
    "            \"created_at\": conv[\"created_at\"],\n",
    "            \"last_activity\": conv[\"last_activity\"],\n",
    "            \"message_count\": len(messages)\n",
    "        })\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error retrieving conversation: {str(e)}\")\n",
    "        return jsonify({\"error\": f\"Error retrieving conversation: {str(e)}\"}), 500\n",
    "\n",
    "@app.route('/api/conversation/<session_id>', methods=['DELETE'])\n",
    "def clear_conversation(session_id):\n",
    "    \"\"\"Clear conversation history\"\"\"\n",
    "    try:\n",
    "        if session_id in conversations:\n",
    "            del conversations[session_id]\n",
    "            logger.info(f\"Conversation cleared for session: {session_id[:8]}...\")\n",
    "        return jsonify({\"message\": \"Conversation cleared successfully\"})\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error clearing conversation: {str(e)}\")\n",
    "        return jsonify({\"error\": f\"Error clearing conversation: {str(e)}\"}), 500\n",
    "\n",
    "@app.route('/api/health', methods=['GET'])\n",
    "def health_check():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return jsonify({\n",
    "        \"status\": \"healthy\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"version\": \"1.1.0\",\n",
    "        \"ai_service\": \"available\" if client else \"unavailable\",\n",
    "        \"active_conversations\": len(conversations)\n",
    "    })\n",
    "\n",
    "@app.route('/api/test', methods=['GET', 'POST'])\n",
    "def test_endpoint():\n",
    "    \"\"\"Test endpoint for debugging\"\"\"\n",
    "    return jsonify({\n",
    "        \"message\": \"API is working correctly\",\n",
    "        \"method\": request.method,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"config\": {\n",
    "            \"model\": Config.MODEL_NAME,\n",
    "            \"base_url\": Config.OPENAI_BASE_URL,\n",
    "            \"api_key_configured\": bool(Config.OPENAI_API_KEY and len(Config.OPENAI_API_KEY) > 10),\n",
    "            \"client_initialized\": client is not None\n",
    "        },\n",
    "        \"headers\": dict(request.headers)\n",
    "    })\n",
    "\n",
    "@app.errorhandler(404)\n",
    "def not_found(error):\n",
    "    logger.warning(f\"404 - Path not found: {request.path}\")\n",
    "    return jsonify({\"error\": \"Endpoint not found\", \"path\": request.path}), 404\n",
    "\n",
    "@app.errorhandler(500)\n",
    "def internal_error(error):\n",
    "    logger.error(f\"500 - Internal server error: {str(error)}\")\n",
    "    return jsonify({\"error\": \"Internal server error\"}), 500\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the app\"\"\"\n",
    "    try:\n",
    "        logger.info(\"=\" * 50)\n",
    "        logger.info(\"Starting Advanced AI Chatbot Server\")\n",
    "        logger.info(\"=\" * 50)\n",
    "       \n",
    "        # Log configuration\n",
    "        logger.info(f\"Model: {Config.MODEL_NAME}\")\n",
    "        logger.info(f\"Base URL: {Config.OPENAI_BASE_URL}\")\n",
    "        logger.info(f\"API Key configured: {bool(Config.OPENAI_API_KEY)}\")\n",
    "        logger.info(f\"Client initialized: {client_initialized}\")\n",
    "       \n",
    "        if not client_initialized:\n",
    "            logger.warning(\"WARNING: OpenAI client failed to initialize!\")\n",
    "            logger.warning(\"The server will start but AI features may not work.\")\n",
    "       \n",
    "        # Start the server\n",
    "        logger.info(\"Starting Flask server on http://0.0.0.0:5000\")\n",
    "        logger.info(\"Visit http://localhost:5000 to test the chatbot\")\n",
    "        logger.info(\"API endpoints available at /api/*\")\n",
    "       \n",
    "        app.run(\n",
    "            debug=False,  # Disable debug mode to prevent reloader issues\n",
    "            host='0.0.0.0',\n",
    "            port=5000,\n",
    "            threaded=True\n",
    "        )\n",
    "       \n",
    "    except KeyboardInterrupt:\n",
    "        logger.info(\"\\nServer stopped by user (Ctrl+C)\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to start server: {str(e)}\", exc_info=True)\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
